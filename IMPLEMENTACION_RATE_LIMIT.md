# âœ… ImplementaciÃ³n: Rate Limiting Distribuido V2

## ğŸ“ Archivos Creados/Modificados

```
api/
â”œâ”€â”€ recommend.ts              # âœ… Actualizado - Usa nuevo rate limiter
â””â”€â”€ utils/
    â”œâ”€â”€ rateLimit.ts          # ğŸ†• Nuevo - LÃ³gica de rate limiting atÃ³mico
    â””â”€â”€ README.md             # ğŸ†• Nuevo - DocumentaciÃ³n

src/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useRateLimit.ts       # ğŸ†• Nuevo - Hook React para frontend
â””â”€â”€ components/
    â””â”€â”€ RecommendationScreen.tsx  # âœ… Actualizado - Muestra rate limit UI
```

## ğŸ¯ Cambios Clave

### 1. Backend: Transacciones AtÃ³micas

**Antes (V1):**
```typescript
// Race condition: 2 instancias pueden pasar al mismo tiempo
const recentSnap = await db.collection('user_interactions')
  .where('userId', '==', userId)
  .get();
// ... verificaciÃ³n ...
```

**DespuÃ©s (V2):**
```typescript
// TransacciÃ³n atÃ³mica garantiza consistencia
return await this.db.runTransaction<RateLimitResult>(async (t) => {
  const doc = await t.get(counterRef);
  // ... verificaciÃ³n dentro de transacciÃ³n ...
  t.set(counterRef, newRecord, { merge: true });
});
```

### 2. Frontend: Feedback Visual

- BotÃ³n muestra tiempo restante cuando hay rate limit
- Contador de requests restantes en los Ãºltimos 10 min
- Indicador visual amarillo cuando hay espera

### 3. API: Endpoint de Status

```bash
GET /api/recommend?userId=xxx
```

Respuesta:
```json
{
  "requestsInWindow": 2,
  "canRequest": true,
  "nextAvailableIn": 0,
  "remainingRequests": 3
}
```

## ğŸ“Š Beneficios de la ImplementaciÃ³n

| MÃ©trica | V1 | V2 | Mejora |
|---------|-----|-----|--------|
| Race Conditions | âœ… SÃ­ | âŒ No | 100% |
| Lecturas/check | 2-10 | 1 | 80% menos |
| Consistencia | Eventual | Fuerte | AtÃ³mica |
| User Experience | Error 429 sorpresa | Indicador previo | Mejor |

## ğŸ§ª Testing Manual

### 1. Verificar rate limit bÃ¡sico
```bash
# Hacer 6 requests rÃ¡pidas
for i in {1..6}; do
  curl -X POST https://tu-api.vercel.app/api/recommend \
    -H "Content-Type: application/json" \
    -d '{"userId":"test123","type":"En casa","mealType":"Desayuno"}'
  echo ""
done
```

**Esperado:**
- Requests 1-5: Ã‰xito (200)
- Request 6: Rate limit (429) con `retryAfter`

### 2. Verificar endpoint de status
```bash
curl "https://tu-api.vercel.app/api/recommend?userId=test123"
```

**Esperado:**
```json
{
  "requestsInWindow": 5,
  "canRequest": false,
  "nextAvailableIn": 45
}
```

### 3. Verificar cleanup de procesos atascados
```bash
# Iniciar request y cancelarla a los 5 segundos
curl -X POST ... &
sleep 5 && kill $!

# Intentar nuevo request inmediatamente
curl -X POST ...
```

**Esperado:** Segunda request debe funcionar (proceso anterior marcado como atascado y limpiado)

## ğŸ“ˆ Monitoreo Recomendado

Agregar en `rateLimit.ts`:
```typescript
// Log estructurado para anÃ¡lisis
console.log(JSON.stringify({
  event: 'rate_limit_check',
  userId,
  allowed: result.allowed,
  requestsInWindow: validRequests.length,
  timestamp: new Date().toISOString()
}));
```

MÃ©tricas a seguir:
1. **Rate limit hits/day** - Ajustar lÃ­mites si es muy alto/bajo
2. **Stuck process cleanups/day** - Detectar problemas de timeout
3. **Tiempo promedio de procesamiento** - Ajustar `stuckThresholdMs`

## ğŸ”’ Seguridad

- âœ… Transacciones atÃ³micas evitan bypass del rate limit
- âœ… Fail-open: Si Firestore falla, permite request (evita bloqueos totales)
- âœ… User ID siempre validado antes de operaciones

## ğŸš€ Deployment Checklist

- [ ] Deploy a staging
- [ ] Probar rate limit con 10+ requests seguidas
- [ ] Verificar que el cleanup de stuck processes funciona
- [ ] Probar el endpoint GET de status
- [ ] Verificar que el frontend muestra el indicador correctamente
- [ ] Deploy a producciÃ³n
- [ ] Monitorear logs por 24h

## ğŸ“ Notas

- **Backwards compatible:** El endpoint POST mantiene la misma interfaz
- **MigraciÃ³n gradual:** La colecciÃ³n `rate_limit_v2` se crea automÃ¡ticamente
- **Limpieza automÃ¡tica:** Los documentos antiguos se pueden eliminar con TTL si es necesario
