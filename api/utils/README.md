# Rate Limiting Distribuido V2

## ğŸ¯ Problema Resuelto

El rate limiting anterior tenÃ­a **race conditions** cuando mÃºltiples instancias serverless verificaban simultÃ¡neamente. Con 10,000 usuarios, un usuario podÃ­a disparar 5-10 requests antes de que el primero se registrara.

## âœ… SoluciÃ³n

Usamos **transacciones atÃ³micas de Firestore** que garantizan:
- âœ… Consistencia entre mÃºltiples instancias serverless
- âœ… Una sola lectura/escritura por verificaciÃ³n (mÃ¡s eficiente)
- âœ… Auto-cleanup de procesos atascados
- âœ… Ventana deslizante de requests

## ğŸ“Š ComparaciÃ³n de Costos

| MÃ©trica | V1 (Antiguo) | V2 (Nuevo) | Ahorro |
|---------|-------------|-----------|--------|
| Lecturas por check | 2-10+ (query + scan) | 1 (transacciÃ³n) | ~80% |
| Escrituras por proceso | 2-3 | 1-2 | ~40% |
| Race conditions | SÃ­ | No | 100% |

## ğŸ”§ Uso

### En el Backend (API)

```typescript
import { rateLimiter } from './utils/rateLimit';

// Verificar rate limit
const check = await rateLimiter.checkRateLimit(userId);
if (!check.allowed) {
  return res.status(429).json({ 
    error: check.error,
    retryAfter: check.secondsLeft 
  });
}

// Proceso exitoso
await rateLimiter.completeProcess(userId);

// Proceso fallido (no cuenta para rate limit)
await rateLimiter.failProcess(userId, errorMessage);
```

### En el Frontend

```typescript
// Verificar status antes de permitir click
const checkRateLimit = async () => {
  const response = await fetch(`/api/recommend?userId=${userId}`);
  const status = await response.json();
  
  if (!status.canRequest) {
    const seconds = status.nextAvailableIn;
    showToast(`Espera ${seconds} segundos...`);
    return false;
  }
  return true;
};
```

## ğŸ” Debugging

### Ver estado de un usuario
```bash
curl "https://tu-api.vercel.app/api/recommend?userId=USER_ID"
```

Respuesta:
```json
{
  "requestsInWindow": 2,
  "canRequest": true,
  "nextAvailableAt": 1707345600000,
  "nextAvailableIn": 15
}
```

### Reset manual (para soporte)
```typescript
import { rateLimiter } from './utils/rateLimit';

// Limpiar todos los lÃ­mites de un usuario
await rateLimiter.resetUser(userId);
```

## âš™ï¸ ConfiguraciÃ³n

```typescript
import { DistributedRateLimiter } from './utils/rateLimit';

const customLimiter = new DistributedRateLimiter({
  windowMs: 10 * 60 * 1000,      // 10 minutos
  maxRequests: 5,                 // 5 requests por ventana
  cooldownMs: 30 * 1000,          // 30 segundos entre requests
  stuckThresholdMs: 2 * 60 * 1000 // 2 minutos para cleanup
});
```

## ğŸ—‚ï¸ Estructura de Datos en Firestore

```
rate_limit_v2/{userId}
â”œâ”€â”€ requests: [1707345600000, 1707345660000, ...]  // Timestamps
â”œâ”€â”€ currentProcess: {
â”‚     startedAt: 1707345720000,
â”‚     interactionId: "proc_1707345720000"
â”‚   }
â”œâ”€â”€ updatedAt: Timestamp
â””â”€â”€ metadata: {
      cleanedAt: Timestamp,
      cleanReason: "stuck_timeout",
      lastError: {...}
    }
```

## ğŸš¨ MigraciÃ³n desde V1

1. Desplegar nuevo cÃ³digo
2. El sistema funciona en paralelo (no afecta user_interactions existentes)
3. Opcional: Migrar datos antiguos si es necesario mantener histÃ³rico exacto
4. DespuÃ©s de 24h, eliminar lÃ³gica V1 del cÃ³digo

## ğŸ“ˆ Monitoreo

Recomendado: Agregar logs estructurados para:
- Rate limit hits (para ajustar lÃ­mites)
- Stuck process cleanups (para detectar problemas)
- Tiempo promedio de procesamiento
